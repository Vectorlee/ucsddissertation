\section{Introduction}
\label{sec:introduction}

Over the last decade, the use of threat information sharing ---
commonly labeled ``threat intelligence'' --- has become a staple
in any discussion of network defense.  The premise is that by broadly
sharing information about known threats, organizations can better
protect themselves in advance of a future attack.  From this basic
idea, a burgeoning industry has emerged to collect, aggregate, curate
and distribute such information~\cite{tipredict2018, tounsi2018survey},
largely consisting of lists of IP
addresses, domain names or URLs thought to be associated with
particular classes of threats (a.k.a., \textit{indicators of
  compromise} or IOCs).

In turn, threat intelligence data of this sort can be used in a number
of distinct ways.  It can be used forensically during incident response
(i.e., to better understand and attribute a threat after it has gained
purchase in a network), it can be used reactively to generate alerts
of suspicious activity (i.e., to raise awareness of a potential threat
that is currently active), or it can be used proactively to block
traffic (and hence block the associated threats).  This last category
of action, traditionally called ``blacklisting'', is uniquely
attractive to a defender since, if effective, it can foreclose certain
threats without requiring individualized attention from a human
analyst.  Indeed, it is common to see such precisely scenarios
highlighted in the marketing materials for virtually all threat
intelligence offerings.

%However, it far from clear if this promise of threat intelligence in
%the abstract is matched by its implementation in practice.
However, despite all the promises, it is far from clear how people adopt
threat intelligence data, especially for proactive traffic blocking.
Proactively blocking traffic based on threat intelligence data is a strong
action, and recent work by Li et al.~\cite{li2019reading} has shown that
threat intelligence feeds can be far from comprehensive and may include
significant numbers of false positives. This could cause an organization
to inadvertently block benign Internet sites. Moreover, on a broader scale,
a mistakenly added IP in a threat intelligence feed can
effectively be denied service from all organizations using that feed
to block traffic. Given this, it is important to understand the extent
to which network administrators are willing to use such third-party data to
block network traffic.

%Exploring this question is the focus of this paper.
In this paper, we take the first look into this question. In particular,
we seek to better understand the extent to which network administrators
make use of threat intelligence IP feeds(more commonly known as IP blacklists)
to proactively block network traffic and, if they do, which kinds of data
sources are they using for that purpose.

The principal challenge in pursuing this question is that such
decisions are largely invisible: a network choosing to block IP
address x, is indistinguishable from one that does not, except to the
owner of IP address x.  Moreover, for operational security reasons,
few organizations are willing to publicly document the details of
their network defenses.  Thus, there is no crisp mechanism to
determine if a network blocks certain traffic, let alone a means to
determine the data source driving such a decision.

In this paper, we explore this question via a combination of inference
and careful testing, resulting in three primary contributions.
First, building on prior work designed to detect
censorship~\cite{ensafi2014detecting, pearce2017augur}, we develop,
test and validate an inference technique using the IP ID side-channel to
detect network-layer blacklisting.  Second, by using this technique with a
carefully chosen set of IP addresses, we are able to attribute
blocking actions to the use of particular blacklists.  Finally, we conduct a
large-scale pilot study covering over {\reflroughnum} U.S. hosts
to explore the diversity in blacklisting behaviors. Together, we
uncover the use of {\blacklistnum} popular public IP blacklists among
the hosts we surveyed, and demonstrate relations between these hosts
and their update pattern on blacklists. We further investigate a broader
use of blacklists among our hosts, and discovered over 73K hosts has
shown blacklist related blocking behavior.

%(including the
%existence of country-specific geo-blocking, the popularity of
%particular public blacklists, and the clear evidence of private
%blacklist use).




%In summary, our contributions are:
%\begin{itemize}
%    \item Developed the techniques to conduct fast and accurate connectivity
%    measurements using IP ID side channel.
%    \item Measured over {\reflroughnum} hosts in United States and reasoned their
%    blocking behavior over {\blacklistnum} popular public threat intelligence IP feeds.
%   \item Studied the update behavior of organizations respect to the threat intelligence
%    feed they are using.
%    \item Identified different interfering cases in this measurement that
%    previous work fail to address, and demonstrate the method to filter them.
%    \item Explored the consistency of blocking behavior between hosts within the
%    same network.
%    \item Demonstrate the security related network blocking in general and highlighted
%    notable cases.
%\end{itemize}



%The utility of such data depends on a variety of factors including
%comprehensiveness (i.e., what fraction of known threats does the
%data cover?), predictive power (i.e., is the recipient of an IOC
%likely to encounter that threat?) and accuracy (i.e., how often does an
%IOC incorrectly label a benign resource?).  In addition,


%this technique to detect threat intelligence related
%network blocking. But we have to tackle a few challenges to make this measurement
%possible. First, the threat intelligence feeds are not static but updating their
%data frequently, and also the large scale analysis will involve tens of millions
%of individual tests, so the measurement technique have to be efficient to finish
%large volume of tests and produce reliable results. Second, most IPs in threat
%intelligence feeds are not active(not responding to TCP SYN probe), forcing us
%to change the original techinque to hanlde our experiment. Finally, there are
%many other network blocking behaviors that could mislead our results, like
%geo-blocking and unroutable IPs(see Section~\ref{sec:methodology}). We need to
%filter out these interfering signals to get genuine result.


%This ``intelligence'' can take
%many forms, like vulnerability reports, network traffic patterns for certain
%malware, or conversation threads from underground forums that include notable
%topics of discussion between potential attackers. Among these different formats,
%the most common form of threat intelligence is
%simple observable forensic data that identify potentially malicious activities
%obn a system or network. These include network indicators such as IP addresses
%(e.g. addresses that known to launch particular attacks), domains (e.g.
%domains that are associated with malware's command-and-control servers),
%phish URLs or file hashes of a particular variety of malware. The promise of
%these indicators is that they can act as early warning signs for
%administrators to take action on while also being used as reference during
%security forensic analysis. These indicators are what most threat
%intelligence products focus on.



%Network security devices, such as firewalls or intrusion prevension
%appliances, support two key fuctions: first, they can restrict access to hosts
%and services that have a compelling reason to be public facing and
%second, they provide the ability to block ``known bad'' traffic from
%entering the network.  This second capability relies on the
%availability of contemporary and accurate information about network
%threats.  Blacklists, frequently now incorporated into the more
%fashionable term ``threat intelligence'', support this need and are


%The primary draw of threat intelligence is that it can help organizations
%better understand and mitigate cyberattacks.

%In recent years, there has been a surge in the number of Threat Intelligence
%products in the market. Both established security firms, and newer companies
%offer a wide range of threat intelligence products. In addition to the
%commercial products, providers of ``public'' threat intelligence too are
%getting increasing attention. In fact, the global threat intelligence marker
%is predicted to surpass \$13 Billion in 2025~\cite{tipredict2018}. Given this
%market interest, we have also seen a corresponding increase in research work
%related to threat intelligence~\cite{tounsi2018survey}. The primary focus of
%this line of research has been on the characterizing threat intelligence
%feeds, and look at their effectiveness and ways to further improve them.

%However, there is one important aspect of threat intelligence that little work
%has looked into before: which and how threat intelligence feeds are being
%actually used. Understanding this aspect of threat intelligence use is important
%as it tells us the adoption of the data, which is essential information to know
%in the threat intelligence ecosystem. More critically, the usage of threat
%intelligence gives us valuable insight into the potential impact it could have
%on the Internet. As recent work has shown~\cite{li2019reading}, false positives
%are relatively common in threat intelligence feeds. If an organization uses a
%threat intelligence feed to block IP traffic, and there is a false positive(a benign IP address)
%in this feed, it effectively cuts of the organization from accessing that
%benign IP address -- an IP that could potentially host an useful service. From
%the other side, if one online host is added to an IP feed mistakenly, then this
%host will lose access to all the organizations that use this feed as a blocking
%ruleset. Thus, the usage problem is a crucial topic that should get more
%attention from the security community.

%That said, this is a challenging problem. Primarily this is because the data
%from threat intelligence feeds can be used in may different ways. The data
%can be used to directly block network traffic, or just raise an alarm in
%their Security Information and Event Management(SIEM) systems. Moreover, some
%use cases do not even have a well-defined behavior that we can quantitatively
%measure. The actions derived from threat intelligence data can also happen at
%different layers. For example, an organization can deny access at the network
%layer (e.g. block traffic from reaching the host), or at the transport layer
%(e.g. prevent TCP handsake by responding SYN requests with RST), it can
%also deny access at the application layer (e.g. HTTP 403 Forbidden).
%These diverse possibilities make it very challenge to assess this problem
%as a whole. Finally, as academic researchers we do not have access to
%commercial threat intelligence data, as they can be prohibitively expensive.
%Hence, it is hard to capture a comprehensive picture of threat intelligence
%usage on the Internet.

%In this paper, we focus on one specific way of using threat intelligence
%data: IP-based network layer traffic blocking. In this use case, the user
%takes the threat intelligence IP product and block incoming traffic when the
%source IPs match the addresses in the product. This is a well-defined use
%case and has a clear network behavior to observe: network connection
%blocking. Focusing on this use case enables us to concretely measure the
%behavior and argue about the implications. As for the threat intelligence
%feeds, we use the public threat intelligence IP feeds and measure their
%usage. Although this would only give us a limited view, previous work has
%shown~\cite{li2019reading} that commercial products tend to include data from
%public sources. Therefore, we can use public data feeds as a way to gain
%knowledge about the commercial world. Finally, we conduct the measurement
%over a large number of online hosts against a diverse set of public IP feeds,
%to acquire a broad view of the usage on the Internet.

%However, measuring this one particular use case is still a non-trivial
%problem. Other network connection blocking studies, like censorship studies
%or geo-blocking measurement, mainly relay on having vantage points. For
%example, having a machine located in the target country when measuring
%geo-blocking~\cite{mcdonald2018403}. However, in our case, we do not have
%control over threat intelligence IP feeds, so we can not put our machine IPs
%into these lists to facilitate our measurement. On the other end, we intend
%to conduct a large scale measurement to evaluate how the IP feeds are used on
%the Internet, which makes it unrealistic to acquire access to all those
%machines we want to measure. Thus, to make this measurement possible we need
%a technique to measure, from a neutral vantage point, if some host online
%blocks traffic to another host.


%possibility of using TCP/IP side-channels to measure network connectivity
%between two hosts online, where the measurement does not need to have access
%to either of these two hosts. Specifically, these works use the IP ID
%side-channel, wherein any online hosts that have a shared global IP ID
%counter, and do not generate much traffic can be used to measure whether it
%is connectable to any other host online.
